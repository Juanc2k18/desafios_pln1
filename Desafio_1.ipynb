{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Resolución del desafio 1\n",
        "Alumno: Juan Miguel Chunga"
      ],
      "metadata": {
        "id": "uzzqgDV8fQ-e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**Nota: Cada experimento realizado debe estar acompañado de una explicación o interpretación de lo observado.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalacion de paquetes y carga de modulos"
      ],
      "metadata": {
        "id": "29JbLcX5fkgr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLyYEVvfyw9q",
        "outputId": "c919f177-2506-4fc7-fbcc-512856be1a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1\n",
        "\n",
        "Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación."
      ],
      "metadata": {
        "id": "2RuwFQgugXVO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftPlyanuak8n",
        "outputId": "f0cc94c2-6f4a-415a-f9df-6fcf54cb91e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ]
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "print(newsgroups_train.data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "8ddb19b1-7ede-48f2-fa41-8d5720a43215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "Cantidad de documentos: 11314\n",
            "Tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'Cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'Tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "0cd1f397-84e7-442d-fa29-287f1ef0a8a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# una vez fiteado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avances parciales\n",
        "\n",
        "* Se ha elaborado el set de entrenamiento\n",
        "* Se han vectorizado los documentos\n",
        "* Se piden seleccionar 5 documentos de manera aleatoria. Para ello, se obtendran 5 numeros de manera aleatoria. La semilla sera fija para garantizar repetitividad."
      ],
      "metadata": {
        "id": "ejbrUh6DnDVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtencion de numeros al azar\n",
        "import random\n",
        "\n",
        "# Fijar la semilla para reproducibilidad\n",
        "random.seed(42)\n",
        "\n",
        "# Generar una lista de 5 números aleatorios entre 0 y el tamaño de X_train\n",
        "random_indices = [random.randint(0, X_train.shape[0]-1) for _ in range(5)]\n",
        "print(random_indices)\n",
        "# Los documentos seran [10476, 1824, 409, 4506, 4012]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzJsyxiGn_0G",
        "outputId": "4ffb04b2-d2ca-4d41-8866-e1fd7bc1b847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10476, 1824, 409, 4506, 4012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "5ef4fc42-a201-428e-831b-842ac9bc7eda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "99cc9d99-5e1d-450a-9917-8a00176e7105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "42665042-7aff-4a7c-c6ea-abf836b1968f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE WHITE HOUSE\n",
            "\n",
            "                  Office of the Press Secretary\n",
            "                   (Pittsburgh, Pennslyvania)\n",
            "______________________________________________________________\n",
            "For Immediate Release                         April 17, 1993     \n",
            "\n",
            "             \n",
            "                  RADIO ADDRESS TO THE NATION \n",
            "                        BY THE PRESIDENT\n",
            "             \n",
            "                Pittsburgh International Airport\n",
            "                    Pittsburgh, Pennsylvania\n",
            "             \n",
            "             \n",
            "10:06 A.M. EDT\n",
            "             \n",
            "             \n",
            "             THE PRESIDENT:  Good morning.  My voice is coming to\n",
            "you this morning through the facilities of the oldest radio\n",
            "station in America, KDKA in Pittsburgh.  I'm visiting the city to\n",
            "meet personally with citizens here to discuss my plans for jobs,\n",
            "health care and the economy.  But I wanted first to do my weekly\n",
            "broadcast with the American people. \n",
            "             \n",
            "             I'm told this station first broadcast in 1920 when\n",
            "it reported that year's presidential elections.  Over the past\n",
            "seven decades presidents have found ways to keep in touch with\n",
            "the people, from whistle-stop tours to fire-side chats to the bus\n",
            "tour that I adopted, along with Vice President Gore, in last\n",
            "year's campaign.\n",
            "             \n",
            "             Every Saturday morning I take this time to talk with\n",
            "you, my fellow Americans, about the problems on your minds and\n",
            "what I'm doing to try and solve them.  It's my way of reporting\n",
            "to you and of giving you a way to hold me accountable.\n",
            "             \n",
            "             You sent me to Washington to get our government and\n",
            "economy moving after years of paralysis and policy and a bad\n",
            "experiment with trickle-down economics.  You know how important\n",
            "it is for us to make bold, comprehensive changes in the way we do\n",
            "business.  \n",
            "             \n",
            "             We live in a competitive global economy.  Nations\n",
            "rise and fall on the skills of their workers, the competitiveness\n",
            "of their companies, the imagination of their industries, and the\n",
            "cooperative experience and spirit that exists between business,\n",
            "labor and government.  Although many of the economies of the\n",
            "industrialized world are now suffering from slow growth, they've\n",
            "made many of the smart investments and the tough choices which\n",
            "our government has for too long ignored.  That's why many of them\n",
            "have been moving ahead and too many of our people have been\n",
            "falling behind.\n",
            "             \n",
            "             We have an economy today that even when it grows is\n",
            "not producing new jobs.  We've increased the debt of our nation\n",
            "by four times over the last 12 years, and we don't have much to\n",
            "show for it.  We know that wages of most working people have\n",
            "stopped rising, that most people are working longer work weeks\n",
            "and that too many families can no longer afford the escalating\n",
            "cost of health care.\n",
            "             \n",
            "             But we also know that, given the right tools, the\n",
            "right incentives and the right encouragement, our workers and\n",
            "businesses can make the kinds of products and profits our economy\n",
            "needs to expand opportunity and to make our communities better\n",
            "places to live.\n",
            "             \n",
            "             In many critical products today Americans are the\n",
            "low cost, high quality producers.  Our task is to make sure that\n",
            "we create more of those kinds of jobs.\n",
            "             \n",
            "             Just two months ago I gave Congress my plan for\n",
            "long-term jobs and economic growth.  It changes the old\n",
            "priorities in Washington and puts our emphasis where it needs to\n",
            "be -- on people's real needs, on increasing investments and jobs\n",
            "and education, on cutting the federal deficit, on stopping the\n",
            "waste which pays no dividends, and redirecting our precious\n",
            "resources toward investment that creates jobs now and lays the\n",
            "groundwork for robust economic growth in the future.\n",
            "             \n",
            "             These new directions passed the Congress in record\n",
            "time and created a new sense of hope and opportunity in our\n",
            "country.  Then the jobs plan I presented to Congress, which would\n",
            "create hundreds of thousands of jobs, most of them in the private\n",
            "sector in 1993 and 1994, passed the House of Representatives.  It\n",
            "now has the support of a majority of the United States Senate. \n",
            "But it's been held up by a filibuster of a minority in the\n",
            "Senate, just 43 senators.  They blocked a vote that they know\n",
            "would result in the passage of our bill and the creation of jobs.\n",
            "             \n",
            "             The issue isn't politics; the issue is people. \n",
            "Millions of Americans are waiting for this legislation and\n",
            "counting on it, counting on us in Washington.  But the jobs bill\n",
            "has been grounded by gridlock.  \n",
            "             \n",
            "             I know the American people are tired of business as\n",
            "usual and politics as usual.  I know they don't want us to spin\n",
            "or wheels.  They want the recovery to get moving.  So I have\n",
            "taken a first step to break this gridlock and gone the extra\n",
            "mile.  Yesterday I offered to cut the size of this plan by 25\n",
            "percent -- from $16 billion to $12 billion.  \n",
            "             \n",
            "             It's not what I'd hoped for.  With 16 million\n",
            "Americans looking for full-time work, I simply can't let the bill\n",
            "languish when I know that even a compromise bill will mean\n",
            "hundreds of thousands of jobs for our people.  The mandate is to\n",
            "act to achieve change and move the country forward.  By taking\n",
            "this initiative in the face of an unrelenting Senate talkathon, I\n",
            "think we can respond to your mandate and achieve a significant\n",
            "portion of our original goals.\n",
            "             \n",
            "             First, we want to keep the programs as much as\n",
            "possible that are needed to generate jobs and meet human needs,\n",
            "including highway and road construction, summer jobs for young\n",
            "people, immunization for children, construction of waste water\n",
            "sites, and aid to small businesses.  We also want to keep funding\n",
            "for extended unemployment compensation benefits, for people who\n",
            "have been unemployed for a long time because the economy isn't\n",
            "creating jobs.\n",
            "             \n",
            "             Second, I've recommended that all the other programs\n",
            "in the bill be cut across-the-board by a little more than 40\n",
            "percent.\n",
            "             \n",
            "             And third, I've recommended a new element in this\n",
            "program to help us immediately start our attempt to fight against\n",
            "crime by providing $200 million for cities and towns to rehire\n",
            "police officers who lost their jobs during the recession and put\n",
            "them back to work protecting our people.  I'm also going to fight\n",
            "for a tough crime bill because the people of this country need it\n",
            "and deserve it.\n",
            "             \n",
            "             Now, the people who are filibustering this bill --\n",
            "the Republican senators -- say they won't vote for it because it\n",
            "increases deficit spending, because there's extra spending this\n",
            "year that hasn't already been approved.  That sounds reasonable,\n",
            "doesn't it?  Here's what they don't say.  This program is more\n",
            "than paid for by budget cuts over my five-year budget, and this\n",
            "budget is well within the spending limits already approved by the\n",
            "Congress this year.\n",
            "             \n",
            "             It's amazing to me that many of these same senators\n",
            "who are filibustering the bill voted during the previous\n",
            "administration for billions of dollars of the same kind of\n",
            "emergency spending, and much of it was not designed to put the\n",
            "American people to work.  \n",
            "             \n",
            "             This is not about deficit spending.  We have offered\n",
            "a plan to cut the deficit.  This is about where your priorities\n",
            "are -- on people or on politics.  \n",
            "             \n",
            "             Keep in mind that our jobs bill is paid for dollar\n",
            "for dollar.  It is paid for by budget cuts.  And it's the\n",
            "soundest investment we can now make for ourselves and our\n",
            "children.  I urge all Americans to take another look at this jobs\n",
            "and investment program; to consider again the benefits for all of\n",
            "us when we've helped make more American partners working to\n",
            "ensure the future of our nation and the strength of our economy.\n",
            "             \n",
            "             You know, if every American who wanted a job had\n",
            "one, we wouldn't have a lot of the other problems we have in this\n",
            "country today.  This bill is not a miracle, it's a modest first\n",
            "step to try to set off a job creation explosion in this country\n",
            "again.  But it's a step we ought to take.  And it is fully paid\n",
            "for over the life of our budget.\n",
            "             \n",
            "             Tell your lawmakers what you think.  Tell them how\n",
            "important the bill is.  If it passes, we'll all be winners.\n",
            "             \n",
            "             Good morning, and thank you for listening.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "5ec5a5e3-9d10-4ddd-bc9d-195265a4ef81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "649ea673-989a-49d4-f92f-12786d3cf34c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4811, 6635, 4253, ..., 9019, 9016, 8748])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QdJLHPJACvaj",
        "outputId": "0442292c-5ce8-4d7d-88b4-7d8baf474408"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "356ce188-933c-4f63-e368-fea7a8d4786c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando las herramientas anteriores, se diseñan funciones auxiliares para su ejecucion en los diferentes documentos."
      ],
      "metadata": {
        "id": "azZUEhu7sEwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def comparar_documentos(indice=0):\n",
        "    \"\"\"\n",
        "    Compara un documento contra el resto usando similitud coseno.\n",
        "    Devuelve:\n",
        "      - Tipo del documento origen\n",
        "      - Tabla con los 5 documentos más similares y sus clases\n",
        "    \"\"\"\n",
        "    # Similitud coseno\n",
        "    cossim = cosine_similarity(X_train[indice], X_train)[0]\n",
        "\n",
        "    # Valores y posiciones ordenadas\n",
        "    mostsim_idx = np.argsort(cossim)[::-1][1:6]\n",
        "    cossim_vals = np.sort(cossim)[::-1][1:6]\n",
        "\n",
        "    # Tipo de documento origen\n",
        "    ori_type = newsgroups_train.target_names[y_train[indice]]\n",
        "\n",
        "    # Crear DataFrame para ordenar los datos\n",
        "    df = pd.DataFrame({\n",
        "        \"Indice documento\": mostsim_idx,\n",
        "        \"Similitud coseno\": cossim_vals,\n",
        "        \"Clase destino\": [newsgroups_train.target_names[y_train[i]] for i in mostsim_idx]\n",
        "    })\n",
        "\n",
        "    return ori_type, df\n"
      ],
      "metadata": {
        "id": "bRsMJFgOw6y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de llamado a la funcion\n",
        "ori,tabla=comparar_documentos(0)\n",
        "print(\"Documento origen: \",ori)\n",
        "print(\"Sobre las similitudes identificadas:\")\n",
        "print(tabla)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyCj4J-dxWaz",
        "outputId": "bc7a034a-1aaf-4f49-a954-06c01333072b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento origen:  rec.autos\n",
            "Sobre las similitudes identificadas:\n",
            "   Indice documento  Similitud coseno Clase destino\n",
            "0              8013          0.305865     rec.autos\n",
            "1              2554          0.292249     rec.autos\n",
            "2              5553          0.280730     rec.autos\n",
            "3              8266          0.280169     rec.autos\n",
            "4              5282          0.276992     rec.autos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, se observa que el metodo funciona muy bien, dado que la clase de destino es del mismo tipo, aunque los valores de la similitud coseno son relativamente bajos."
      ],
      "metadata": {
        "id": "OVEao6OW6_A0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documento de indice 10476"
      ],
      "metadata": {
        "id": "ytJ9_Odp8sVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ori,tabla=comparar_documentos(random_indices[0])\n",
        "print(\"Documento origen: \",ori)\n",
        "print(\"Sobre las similitudes identificadas:\")\n",
        "print(tabla)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2id5fKGn8ekW",
        "outputId": "7233d86b-1f19-4bde-e7f0-825ac6cd997e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento origen:  rec.sport.hockey\n",
            "Sobre las similitudes identificadas:\n",
            "   Indice documento  Similitud coseno          Clase destino\n",
            "0              5064          0.225036       rec.sport.hockey\n",
            "1              9623          0.217432  talk.politics.mideast\n",
            "2             10575          0.216444              sci.crypt\n",
            "3             10836          0.212603            alt.atheism\n",
            "4              2350          0.211071              sci.crypt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, el tipo de origen es `rec.sport.hockey`. El documento mas cercano coincide en su tipo, mientras que los demas estan cerca en el espacio vectorial, pero parecen no tener una relacion directa en el tema. Ademas, los valores de la similitud coseno no parecen tener una relevancia alta."
      ],
      "metadata": {
        "id": "uR1sWwJG9Bdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documento 1824"
      ],
      "metadata": {
        "id": "NTSwVJkz80M6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ori,tabla=comparar_documentos(random_indices[1])\n",
        "print(\"Documento origen: \",ori)\n",
        "print(\"Sobre las similitudes identificadas:\")\n",
        "print(tabla)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60af846c-b055-404b-948e-aac20d93e39f",
        "id": "U8s1kxly-Huf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento origen:  comp.sys.mac.hardware\n",
            "Sobre las similitudes identificadas:\n",
            "   Indice documento  Similitud coseno          Clase destino\n",
            "0              9921          0.354198  comp.sys.mac.hardware\n",
            "1              6364          0.313191  comp.sys.mac.hardware\n",
            "2              5509          0.304137  comp.sys.mac.hardware\n",
            "3              2641          0.250383  comp.sys.mac.hardware\n",
            "4              4359          0.241676  comp.sys.mac.hardware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, el tipo de origen es `comp.sys.mac.hardware`. Los 5 documentos mas cercanos coinciden en su tipo. Los valores de la similitud coseno no parecen tener una relevancia alta."
      ],
      "metadata": {
        "id": "v1e_iCPz-7Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documento 409"
      ],
      "metadata": {
        "id": "ok3l6PeI-t7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ori,tabla=comparar_documentos(random_indices[2])\n",
        "print(\"Documento origen: \",ori)\n",
        "print(\"Sobre las similitudes identificadas:\")\n",
        "print(tabla)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HFPMiLb_MiO",
        "outputId": "1f8ecc40-cee8-4e56-a7d0-2a367db82d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento origen:  comp.graphics\n",
            "Sobre las similitudes identificadas:\n",
            "   Indice documento  Similitud coseno  Clase destino\n",
            "0              3444          0.230533  comp.graphics\n",
            "1              5799          0.209073  comp.graphics\n",
            "2              5905          0.198175  comp.graphics\n",
            "3              1764          0.183850  comp.graphics\n",
            "4              3364          0.165854  comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, el tipo de origen es `comp.graphics`. Los 5 documentos mas cercanos coinciden en su tipo. Los valores de la similitud coseno no parecen tener una relevancia alta."
      ],
      "metadata": {
        "id": "LMFmieE9_YMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documento 4506"
      ],
      "metadata": {
        "id": "uyChyjFx-xqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ori,tabla=comparar_documentos(random_indices[3])\n",
        "print(\"Documento origen: \",ori)\n",
        "print(\"Sobre las similitudes identificadas:\")\n",
        "print(tabla)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tkkavae_QIw",
        "outputId": "d42eb751-4abf-4f99-c56b-66ebcaed2f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento origen:  rec.autos\n",
            "Sobre las similitudes identificadas:\n",
            "   Indice documento  Similitud coseno          Clase destino\n",
            "0              4211          0.189361        rec.motorcycles\n",
            "1              5928          0.168237  comp.sys.mac.hardware\n",
            "2              6224          0.158334              rec.autos\n",
            "3              5171          0.157694              rec.autos\n",
            "4              9491          0.152190              rec.autos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, el tipo de origen es `rec.autos`. El documento mas cercano no coincide en su tipo, no obstante, tiene mucha relacion. El segundo documento no aparenta tener una relacion directa, y los ultimos tres documentos son del mismo tipo. Nuevamente, los valores de la similitud coseno no parecen tener una relevancia alta."
      ],
      "metadata": {
        "id": "QmEoYT4Q_epT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documento 4012"
      ],
      "metadata": {
        "id": "ShCe8JV9-zTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ori,tabla=comparar_documentos(random_indices[4])\n",
        "print(\"Documento origen: \",ori)\n",
        "print(\"Sobre las similitudes identificadas:\")\n",
        "print(tabla)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VJJyn_Y_TU0",
        "outputId": "58654666-c618-44a6-9218-034784c3ff3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento origen:  rec.sport.hockey\n",
            "Sobre las similitudes identificadas:\n",
            "   Indice documento  Similitud coseno           Clase destino\n",
            "0              6599          0.160013  soc.religion.christian\n",
            "1             10644          0.142769        rec.sport.hockey\n",
            "2              7478          0.135821        rec.sport.hockey\n",
            "3              7308          0.131774        rec.sport.hockey\n",
            "4             10792          0.130732      rec.sport.baseball\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, el tipo de origen es `rec.sport.hockey`. El documento mas cercano no coincide en su tipo y no muestra relacion aparente. Los siguientes coinciden en tipo hasta el ultimo, que toca otro tipo de deporte. Nuevamente, los valores de la similitud coseno no parecen tener una relevancia alta."
      ],
      "metadata": {
        "id": "hiUgYDDPATpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras observar los experimentos realizados, podemos concluir que la similitud coseno no es suficiente por si misma para detectar documentos similares. Sin embargo, en algunos casos, si es un indicador adecuado de partida.\n",
        "\n",
        "Complementado con otros metodos puede brindar un resultado adecuado."
      ],
      "metadata": {
        "id": "hTUCvlYjDfXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "Construir un modelo de clasificación por prototipos (tipo zero-shot). Clasificar los documentos de un conjunto de test comparando cada uno con todos los de entrenamiento y asignar la clase al label del documento del conjunto de entrenamiento con mayor similaridad."
      ],
      "metadata": {
        "id": "gBLf37jMDCsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para realizar esta actividad, creamos una funcion auxiliar"
      ],
      "metadata": {
        "id": "HsE5NvLUbqaO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ede0f4ea",
        "outputId": "2b96bbdf-03f5-4ace-b247-30d91744b617"
      },
      "source": [
        "def clasificar_zero_shot(vector_doc_prueba, vectores_entrenamiento, labels_entrenamiento):\n",
        "    \"\"\"\n",
        "    Clasifica un documento de prueba utilizando un enfoque zero-shot\n",
        "    basado en la similaridad coseno.\n",
        "\n",
        "    Args:\n",
        "        vector_doc_prueba: Representación vectorial del documento de prueba (matriz dispersa).\n",
        "        vectores_entrenamiento: Matriz dispersa con los vectores de los documentos de entrenamiento.\n",
        "        labels_entrenamiento: Etiquetas correspondientes a los documentos de entrenamiento.\n",
        "\n",
        "    Returns:\n",
        "        La etiqueta de clase predicha para el documento de prueba.\n",
        "    \"\"\"\n",
        "    # Calcular la similaridad coseno entre el documento de prueba y todos los documentos de entrenamiento\n",
        "    similitudes = cosine_similarity(vector_doc_prueba, vectores_entrenamiento)[0]\n",
        "\n",
        "    # Encontrar el índice del documento de entrenamiento más similar\n",
        "    indice_mas_similar = np.argmax(similitudes)\n",
        "\n",
        "    # Devolver la etiqueta correspondiente al documento más similar\n",
        "    return labels_entrenamiento[indice_mas_similar]\n",
        "\n",
        "\n",
        "# Asegurar que X_test y y_test estén definidos transformando el conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "# Aplicar el clasificador zero-shot al conjunto de test\n",
        "print(\"Aplicando el clasificador zero-shot al conjunto de prueba...\")\n",
        "y_pred_zero_shot = []\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    # Clasificar cada documento de prueba individualmente\n",
        "    etiqueta_predicha = clasificar_zero_shot(X_test[i], X_train, y_train)\n",
        "    y_pred_zero_shot.append(etiqueta_predicha)\n",
        "\n",
        "print(\"Clasificación zero-shot completa.\")\n",
        "\n",
        "# Convertir la lista a un array de NumPy para calcular el F1-score\n",
        "y_pred_zero_shot = np.array(y_pred_zero_shot)\n",
        "\n",
        "# Evaluar el desempeño del modelo\n",
        "f1_zero_shot = f1_score(y_test, y_pred_zero_shot, average='macro')\n",
        "\n",
        "print(f\"El clasificador zero-shot obtuvo un F1-score (promedio macro) de {f1_zero_shot:.4f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplicando el clasificador zero-shot al conjunto de prueba...\n",
            "Clasificación zero-shot completa.\n",
            "El clasificador zero-shot obtuvo un F1-score (promedio macro) de 0.5050.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c50cedf1"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "Comparado con el F1-score del modelo Naïve Bayes (0.5854), el desempeño del clasificador zero-shot es menor.\n",
        "\n",
        "Esto sugiere que la simple comparación de similaridad con documentos individuales no captura bien las distribuciones subyacentes de clases, a diferencia de modelos estadísticos como Naïve Bayes, especialmente considerando las bajas similitudes coseno observadas en el ejercicio previo.  \n",
        "\n",
        "El carácter zero-shot proviene de que este método no entrena un modelo para aprender fronteras de decisión, sino que clasifica únicamente usando la similaridad bruta entre documentos.\n",
        "\n",
        "\n",
        "## Principales hallazgos del análisis de datos\n",
        "- Se implementó y evaluó un enfoque de clasificación *zero-shot*, el cual asigna a cada documento de prueba la etiqueta del documento de entrenamiento más similar según la similaridad coseno.\n",
        "- El clasificador zero-shot alcanzó un F1-score (promedio macro) de **0.5050** en el conjunto de prueba.\n",
        "- Este desempeño es inferior al obtenido con el modelo Naïve Bayes, que logró un F1-score de **0.5854**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3\n",
        "\n",
        "Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación (f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial y ComplementNB.\n",
        "\n",
        "**NO cambiar el hiperparámetro ngram_range de los vectorizadores**."
      ],
      "metadata": {
        "id": "VzUBkk-dILHX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "TPM0thDaLk0R",
        "outputId": "1c636a19-4a69-4415-e4a5-dc46374274aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "#ComplementNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "ba488a94-75c0-463f-ebca-20e664992926"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizar los documentos"
      ],
      "metadata": {
        "id": "5SzxgpGRJzpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfvect = TfidfVectorizer()#Vectorizacion por defecto\n",
        "\n",
        "# Fit en train y transform en train\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "y_train = newsgroups_train.target\n",
        "\n",
        "# Solo transform en test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n"
      ],
      "metadata": {
        "id": "R2kD4HvJLMUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ddc86bd"
      },
      "source": [
        "Los documentos se han vectorizado. Ahora, se deben entrenar los modelos de `MultinomialNB` y `ComplementNB`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Definimos los dos modelos\n",
        "mnb = MultinomialNB(alpha=1.0)\n",
        "cnb = ComplementNB(alpha=1.0)\n",
        "\n",
        "# Entrenamiento\n",
        "mnb.fit(X_train, y_train)\n",
        "cnb.fit(X_train, y_train)\n",
        "\n",
        "# Predicción en test\n",
        "y_pred_mnb = mnb.predict(X_test)\n",
        "y_pred_cnb = cnb.predict(X_test)\n",
        "\n",
        "# F1-score macro\n",
        "f1_mnb = f1_score(y_test, y_pred_mnb, average=\"macro\")\n",
        "f1_cnb = f1_score(y_test, y_pred_cnb, average=\"macro\")\n",
        "\n",
        "print(\"MultinomialNB - F1 macro:\", f1_mnb)\n",
        "print(\"ComplementNB  - F1 macro:\", f1_cnb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEKLcrZGKfEn",
        "outputId": "58abab9a-06c5-4c3f-d0fd-a4c765763098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB - F1 macro: 0.5854345727938506\n",
            "ComplementNB  - F1 macro: 0.692953349950875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se rehace el entrenamiento con diferentes configuraciones de alpha."
      ],
      "metadata": {
        "id": "VlbrzLGxK4hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for a in [0.01, 0.1, 0.5, 1.0, 2.0, 5.0]:\n",
        "    cnb = MultinomialNB(alpha=a)\n",
        "    cnb.fit(X_train, y_train)\n",
        "    pred = cnb.predict(X_test)\n",
        "    print(f'Alpha: {a}, F1: {f1_score(y_test, pred, average=\"macro\")}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn0EQmF-OSGS",
        "outputId": "c0748ec8-ae13-4658-dbec-3f5772aa07ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha: 0.01, F1: 0.6828611295250568\n",
            "Alpha: 0.1, F1: 0.6564514103512165\n",
            "Alpha: 0.5, F1: 0.615341523969213\n",
            "Alpha: 1.0, F1: 0.5854345727938506\n",
            "Alpha: 2.0, F1: 0.53998304998563\n",
            "Alpha: 5.0, F1: 0.46885579817739476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos varias configuraciones"
      ],
      "metadata": {
        "id": "m66gjg0uOiAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "min_dfs     = [1, 2, 5]\n",
        "max_dfs     = [0.9, 0.8, 0.7]\n",
        "max_feats   = [None, 20000, 50000]\n",
        "alphas      = [0.1, 0.5, 1.0, 2.0]\n",
        "\n",
        "mejor_f1_mnb  = 0\n",
        "mejor_conf_mnb = None\n",
        "\n",
        "mejor_f1_cnb  = 0\n",
        "mejor_conf_cnb = None\n",
        "\n",
        "for min_df in min_dfs:\n",
        "    for max_df in max_dfs:\n",
        "        for max_features in max_feats:\n",
        "            # nuevo vectorizador\n",
        "            tfidfvect = TfidfVectorizer(\n",
        "                min_df=min_df,\n",
        "                max_df=max_df,\n",
        "                max_features=max_features,\n",
        "            )\n",
        "\n",
        "            # vectorizar train y test\n",
        "            X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "            y_train = newsgroups_train.target\n",
        "\n",
        "            X_test  = tfidfvect.transform(newsgroups_test.data)\n",
        "            y_test  = newsgroups_test.target\n",
        "\n",
        "            for alpha in alphas:\n",
        "                # MultinomialNB\n",
        "                mnb = MultinomialNB(alpha=alpha)\n",
        "                mnb.fit(X_train, y_train)\n",
        "                y_pred_mnb = mnb.predict(X_test)\n",
        "                f1_mnb = f1_score(y_test, y_pred_mnb, average=\"macro\")\n",
        "\n",
        "                print(f\"[MNB] min_df={min_df}, max_df={max_df}, \"\n",
        "                      f\"max_features={max_features}, alpha={alpha} -> F1={f1_mnb:.4f}\")\n",
        "\n",
        "                if f1_mnb > mejor_f1_mnb:\n",
        "                    mejor_f1_mnb = f1_mnb\n",
        "                    mejor_conf_mnb = {\n",
        "                        \"min_df\": min_df,\n",
        "                        \"max_df\": max_df,\n",
        "                        \"max_features\": max_features,\n",
        "                        \"alpha\": alpha\n",
        "                    }\n",
        "\n",
        "                # ComplementNB\n",
        "                cnb = ComplementNB(alpha=alpha)\n",
        "                cnb.fit(X_train, y_train)\n",
        "                y_pred_cnb = cnb.predict(X_test)\n",
        "                f1_cnb = f1_score(y_test, y_pred_cnb, average=\"macro\")\n",
        "\n",
        "                print(f\"[CNB] min_df={min_df}, max_df={max_df}, \"\n",
        "                      f\"max_features={max_features}, alpha={alpha} -> F1={f1_cnb:.4f}\")\n",
        "\n",
        "                if f1_cnb > mejor_f1_cnb:\n",
        "                    mejor_f1_cnb = f1_cnb\n",
        "                    mejor_conf_cnb = {\n",
        "                        \"min_df\": min_df,\n",
        "                        \"max_df\": max_df,\n",
        "                        \"max_features\": max_features,\n",
        "                        \"alpha\": alpha\n",
        "                    }\n",
        "\n",
        "print(\"\\nResultados:\")\n",
        "print(\"\\nMultinomialNB:\")\n",
        "print(\"  config:\", mejor_conf_mnb)\n",
        "print(\"  F1-macro:\", mejor_f1_mnb)\n",
        "\n",
        "print(\"\\nComplementNB:\")\n",
        "print(\"  config:\", mejor_conf_cnb)\n",
        "print(\"  F1-macro:\", mejor_f1_cnb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ_t3IGaOof_",
        "outputId": "859d5fbf-381f-47f2-a894-05bd89240136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MNB] min_df=1, max_df=0.9, max_features=None, alpha=0.1 -> F1=0.6565\n",
            "[CNB] min_df=1, max_df=0.9, max_features=None, alpha=0.1 -> F1=0.6954\n",
            "[MNB] min_df=1, max_df=0.9, max_features=None, alpha=0.5 -> F1=0.6153\n",
            "[CNB] min_df=1, max_df=0.9, max_features=None, alpha=0.5 -> F1=0.6961\n",
            "[MNB] min_df=1, max_df=0.9, max_features=None, alpha=1.0 -> F1=0.5854\n",
            "[CNB] min_df=1, max_df=0.9, max_features=None, alpha=1.0 -> F1=0.6930\n",
            "[MNB] min_df=1, max_df=0.9, max_features=None, alpha=2.0 -> F1=0.5400\n",
            "[CNB] min_df=1, max_df=0.9, max_features=None, alpha=2.0 -> F1=0.6821\n",
            "[MNB] min_df=1, max_df=0.9, max_features=20000, alpha=0.1 -> F1=0.6731\n",
            "[CNB] min_df=1, max_df=0.9, max_features=20000, alpha=0.1 -> F1=0.6796\n",
            "[MNB] min_df=1, max_df=0.9, max_features=20000, alpha=0.5 -> F1=0.6365\n",
            "[CNB] min_df=1, max_df=0.9, max_features=20000, alpha=0.5 -> F1=0.6870\n",
            "[MNB] min_df=1, max_df=0.9, max_features=20000, alpha=1.0 -> F1=0.6077\n",
            "[CNB] min_df=1, max_df=0.9, max_features=20000, alpha=1.0 -> F1=0.6863\n",
            "[MNB] min_df=1, max_df=0.9, max_features=20000, alpha=2.0 -> F1=0.5699\n",
            "[CNB] min_df=1, max_df=0.9, max_features=20000, alpha=2.0 -> F1=0.6828\n",
            "[MNB] min_df=1, max_df=0.9, max_features=50000, alpha=0.1 -> F1=0.6698\n",
            "[CNB] min_df=1, max_df=0.9, max_features=50000, alpha=0.1 -> F1=0.6917\n",
            "[MNB] min_df=1, max_df=0.9, max_features=50000, alpha=0.5 -> F1=0.6245\n",
            "[CNB] min_df=1, max_df=0.9, max_features=50000, alpha=0.5 -> F1=0.6977\n",
            "[MNB] min_df=1, max_df=0.9, max_features=50000, alpha=1.0 -> F1=0.5932\n",
            "[CNB] min_df=1, max_df=0.9, max_features=50000, alpha=1.0 -> F1=0.6926\n",
            "[MNB] min_df=1, max_df=0.9, max_features=50000, alpha=2.0 -> F1=0.5510\n",
            "[CNB] min_df=1, max_df=0.9, max_features=50000, alpha=2.0 -> F1=0.6851\n",
            "[MNB] min_df=1, max_df=0.8, max_features=None, alpha=0.1 -> F1=0.6578\n",
            "[CNB] min_df=1, max_df=0.8, max_features=None, alpha=0.1 -> F1=0.6950\n",
            "[MNB] min_df=1, max_df=0.8, max_features=None, alpha=0.5 -> F1=0.6175\n",
            "[CNB] min_df=1, max_df=0.8, max_features=None, alpha=0.5 -> F1=0.6956\n",
            "[MNB] min_df=1, max_df=0.8, max_features=None, alpha=1.0 -> F1=0.5884\n",
            "[CNB] min_df=1, max_df=0.8, max_features=None, alpha=1.0 -> F1=0.6920\n",
            "[MNB] min_df=1, max_df=0.8, max_features=None, alpha=2.0 -> F1=0.5462\n",
            "[CNB] min_df=1, max_df=0.8, max_features=None, alpha=2.0 -> F1=0.6825\n",
            "[MNB] min_df=1, max_df=0.8, max_features=20000, alpha=0.1 -> F1=0.6727\n",
            "[CNB] min_df=1, max_df=0.8, max_features=20000, alpha=0.1 -> F1=0.6792\n",
            "[MNB] min_df=1, max_df=0.8, max_features=20000, alpha=0.5 -> F1=0.6375\n",
            "[CNB] min_df=1, max_df=0.8, max_features=20000, alpha=0.5 -> F1=0.6872\n",
            "[MNB] min_df=1, max_df=0.8, max_features=20000, alpha=1.0 -> F1=0.6114\n",
            "[CNB] min_df=1, max_df=0.8, max_features=20000, alpha=1.0 -> F1=0.6869\n",
            "[MNB] min_df=1, max_df=0.8, max_features=20000, alpha=2.0 -> F1=0.5759\n",
            "[CNB] min_df=1, max_df=0.8, max_features=20000, alpha=2.0 -> F1=0.6838\n",
            "[MNB] min_df=1, max_df=0.8, max_features=50000, alpha=0.1 -> F1=0.6713\n",
            "[CNB] min_df=1, max_df=0.8, max_features=50000, alpha=0.1 -> F1=0.6915\n",
            "[MNB] min_df=1, max_df=0.8, max_features=50000, alpha=0.5 -> F1=0.6266\n",
            "[CNB] min_df=1, max_df=0.8, max_features=50000, alpha=0.5 -> F1=0.6980\n",
            "[MNB] min_df=1, max_df=0.8, max_features=50000, alpha=1.0 -> F1=0.5962\n",
            "[CNB] min_df=1, max_df=0.8, max_features=50000, alpha=1.0 -> F1=0.6931\n",
            "[MNB] min_df=1, max_df=0.8, max_features=50000, alpha=2.0 -> F1=0.5569\n",
            "[CNB] min_df=1, max_df=0.8, max_features=50000, alpha=2.0 -> F1=0.6859\n",
            "[MNB] min_df=1, max_df=0.7, max_features=None, alpha=0.1 -> F1=0.6588\n",
            "[CNB] min_df=1, max_df=0.7, max_features=None, alpha=0.1 -> F1=0.6951\n",
            "[MNB] min_df=1, max_df=0.7, max_features=None, alpha=0.5 -> F1=0.6191\n",
            "[CNB] min_df=1, max_df=0.7, max_features=None, alpha=0.5 -> F1=0.6955\n",
            "[MNB] min_df=1, max_df=0.7, max_features=None, alpha=1.0 -> F1=0.5913\n",
            "[CNB] min_df=1, max_df=0.7, max_features=None, alpha=1.0 -> F1=0.6919\n",
            "[MNB] min_df=1, max_df=0.7, max_features=None, alpha=2.0 -> F1=0.5511\n",
            "[CNB] min_df=1, max_df=0.7, max_features=None, alpha=2.0 -> F1=0.6825\n",
            "[MNB] min_df=1, max_df=0.7, max_features=20000, alpha=0.1 -> F1=0.6737\n",
            "[CNB] min_df=1, max_df=0.7, max_features=20000, alpha=0.1 -> F1=0.6795\n",
            "[MNB] min_df=1, max_df=0.7, max_features=20000, alpha=0.5 -> F1=0.6380\n",
            "[CNB] min_df=1, max_df=0.7, max_features=20000, alpha=0.5 -> F1=0.6866\n",
            "[MNB] min_df=1, max_df=0.7, max_features=20000, alpha=1.0 -> F1=0.6134\n",
            "[CNB] min_df=1, max_df=0.7, max_features=20000, alpha=1.0 -> F1=0.6867\n",
            "[MNB] min_df=1, max_df=0.7, max_features=20000, alpha=2.0 -> F1=0.5785\n",
            "[CNB] min_df=1, max_df=0.7, max_features=20000, alpha=2.0 -> F1=0.6838\n",
            "[MNB] min_df=1, max_df=0.7, max_features=50000, alpha=0.1 -> F1=0.6718\n",
            "[CNB] min_df=1, max_df=0.7, max_features=50000, alpha=0.1 -> F1=0.6916\n",
            "[MNB] min_df=1, max_df=0.7, max_features=50000, alpha=0.5 -> F1=0.6290\n",
            "[CNB] min_df=1, max_df=0.7, max_features=50000, alpha=0.5 -> F1=0.6979\n",
            "[MNB] min_df=1, max_df=0.7, max_features=50000, alpha=1.0 -> F1=0.5987\n",
            "[CNB] min_df=1, max_df=0.7, max_features=50000, alpha=1.0 -> F1=0.6931\n",
            "[MNB] min_df=1, max_df=0.7, max_features=50000, alpha=2.0 -> F1=0.5620\n",
            "[CNB] min_df=1, max_df=0.7, max_features=50000, alpha=2.0 -> F1=0.6862\n",
            "[MNB] min_df=2, max_df=0.9, max_features=None, alpha=0.1 -> F1=0.6727\n",
            "[CNB] min_df=2, max_df=0.9, max_features=None, alpha=0.1 -> F1=0.6906\n",
            "[MNB] min_df=2, max_df=0.9, max_features=None, alpha=0.5 -> F1=0.6289\n",
            "[CNB] min_df=2, max_df=0.9, max_features=None, alpha=0.5 -> F1=0.6980\n",
            "[MNB] min_df=2, max_df=0.9, max_features=None, alpha=1.0 -> F1=0.5970\n",
            "[CNB] min_df=2, max_df=0.9, max_features=None, alpha=1.0 -> F1=0.6935\n",
            "[MNB] min_df=2, max_df=0.9, max_features=None, alpha=2.0 -> F1=0.5563\n",
            "[CNB] min_df=2, max_df=0.9, max_features=None, alpha=2.0 -> F1=0.6866\n",
            "[MNB] min_df=2, max_df=0.9, max_features=20000, alpha=0.1 -> F1=0.6742\n",
            "[CNB] min_df=2, max_df=0.9, max_features=20000, alpha=0.1 -> F1=0.6806\n",
            "[MNB] min_df=2, max_df=0.9, max_features=20000, alpha=0.5 -> F1=0.6368\n",
            "[CNB] min_df=2, max_df=0.9, max_features=20000, alpha=0.5 -> F1=0.6877\n",
            "[MNB] min_df=2, max_df=0.9, max_features=20000, alpha=1.0 -> F1=0.6095\n",
            "[CNB] min_df=2, max_df=0.9, max_features=20000, alpha=1.0 -> F1=0.6877\n",
            "[MNB] min_df=2, max_df=0.9, max_features=20000, alpha=2.0 -> F1=0.5699\n",
            "[CNB] min_df=2, max_df=0.9, max_features=20000, alpha=2.0 -> F1=0.6835\n",
            "[MNB] min_df=2, max_df=0.9, max_features=50000, alpha=0.1 -> F1=0.6727\n",
            "[CNB] min_df=2, max_df=0.9, max_features=50000, alpha=0.1 -> F1=0.6906\n",
            "[MNB] min_df=2, max_df=0.9, max_features=50000, alpha=0.5 -> F1=0.6289\n",
            "[CNB] min_df=2, max_df=0.9, max_features=50000, alpha=0.5 -> F1=0.6980\n",
            "[MNB] min_df=2, max_df=0.9, max_features=50000, alpha=1.0 -> F1=0.5970\n",
            "[CNB] min_df=2, max_df=0.9, max_features=50000, alpha=1.0 -> F1=0.6935\n",
            "[MNB] min_df=2, max_df=0.9, max_features=50000, alpha=2.0 -> F1=0.5563\n",
            "[CNB] min_df=2, max_df=0.9, max_features=50000, alpha=2.0 -> F1=0.6866\n",
            "[MNB] min_df=2, max_df=0.8, max_features=None, alpha=0.1 -> F1=0.6733\n",
            "[CNB] min_df=2, max_df=0.8, max_features=None, alpha=0.1 -> F1=0.6907\n",
            "[MNB] min_df=2, max_df=0.8, max_features=None, alpha=0.5 -> F1=0.6308\n",
            "[CNB] min_df=2, max_df=0.8, max_features=None, alpha=0.5 -> F1=0.6979\n",
            "[MNB] min_df=2, max_df=0.8, max_features=None, alpha=1.0 -> F1=0.6010\n",
            "[CNB] min_df=2, max_df=0.8, max_features=None, alpha=1.0 -> F1=0.6925\n",
            "[MNB] min_df=2, max_df=0.8, max_features=None, alpha=2.0 -> F1=0.5602\n",
            "[CNB] min_df=2, max_df=0.8, max_features=None, alpha=2.0 -> F1=0.6864\n",
            "[MNB] min_df=2, max_df=0.8, max_features=20000, alpha=0.1 -> F1=0.6742\n",
            "[CNB] min_df=2, max_df=0.8, max_features=20000, alpha=0.1 -> F1=0.6808\n",
            "[MNB] min_df=2, max_df=0.8, max_features=20000, alpha=0.5 -> F1=0.6376\n",
            "[CNB] min_df=2, max_df=0.8, max_features=20000, alpha=0.5 -> F1=0.6879\n",
            "[MNB] min_df=2, max_df=0.8, max_features=20000, alpha=1.0 -> F1=0.6115\n",
            "[CNB] min_df=2, max_df=0.8, max_features=20000, alpha=1.0 -> F1=0.6871\n",
            "[MNB] min_df=2, max_df=0.8, max_features=20000, alpha=2.0 -> F1=0.5752\n",
            "[CNB] min_df=2, max_df=0.8, max_features=20000, alpha=2.0 -> F1=0.6840\n",
            "[MNB] min_df=2, max_df=0.8, max_features=50000, alpha=0.1 -> F1=0.6733\n",
            "[CNB] min_df=2, max_df=0.8, max_features=50000, alpha=0.1 -> F1=0.6907\n",
            "[MNB] min_df=2, max_df=0.8, max_features=50000, alpha=0.5 -> F1=0.6308\n",
            "[CNB] min_df=2, max_df=0.8, max_features=50000, alpha=0.5 -> F1=0.6979\n",
            "[MNB] min_df=2, max_df=0.8, max_features=50000, alpha=1.0 -> F1=0.6010\n",
            "[CNB] min_df=2, max_df=0.8, max_features=50000, alpha=1.0 -> F1=0.6925\n",
            "[MNB] min_df=2, max_df=0.8, max_features=50000, alpha=2.0 -> F1=0.5602\n",
            "[CNB] min_df=2, max_df=0.8, max_features=50000, alpha=2.0 -> F1=0.6864\n",
            "[MNB] min_df=2, max_df=0.7, max_features=None, alpha=0.1 -> F1=0.6736\n",
            "[CNB] min_df=2, max_df=0.7, max_features=None, alpha=0.1 -> F1=0.6908\n",
            "[MNB] min_df=2, max_df=0.7, max_features=None, alpha=0.5 -> F1=0.6336\n",
            "[CNB] min_df=2, max_df=0.7, max_features=None, alpha=0.5 -> F1=0.6979\n",
            "[MNB] min_df=2, max_df=0.7, max_features=None, alpha=1.0 -> F1=0.6033\n",
            "[CNB] min_df=2, max_df=0.7, max_features=None, alpha=1.0 -> F1=0.6927\n",
            "[MNB] min_df=2, max_df=0.7, max_features=None, alpha=2.0 -> F1=0.5647\n",
            "[CNB] min_df=2, max_df=0.7, max_features=None, alpha=2.0 -> F1=0.6864\n",
            "[MNB] min_df=2, max_df=0.7, max_features=20000, alpha=0.1 -> F1=0.6753\n",
            "[CNB] min_df=2, max_df=0.7, max_features=20000, alpha=0.1 -> F1=0.6821\n",
            "[MNB] min_df=2, max_df=0.7, max_features=20000, alpha=0.5 -> F1=0.6391\n",
            "[CNB] min_df=2, max_df=0.7, max_features=20000, alpha=0.5 -> F1=0.6882\n",
            "[MNB] min_df=2, max_df=0.7, max_features=20000, alpha=1.0 -> F1=0.6139\n",
            "[CNB] min_df=2, max_df=0.7, max_features=20000, alpha=1.0 -> F1=0.6874\n",
            "[MNB] min_df=2, max_df=0.7, max_features=20000, alpha=2.0 -> F1=0.5794\n",
            "[CNB] min_df=2, max_df=0.7, max_features=20000, alpha=2.0 -> F1=0.6843\n",
            "[MNB] min_df=2, max_df=0.7, max_features=50000, alpha=0.1 -> F1=0.6736\n",
            "[CNB] min_df=2, max_df=0.7, max_features=50000, alpha=0.1 -> F1=0.6908\n",
            "[MNB] min_df=2, max_df=0.7, max_features=50000, alpha=0.5 -> F1=0.6336\n",
            "[CNB] min_df=2, max_df=0.7, max_features=50000, alpha=0.5 -> F1=0.6979\n",
            "[MNB] min_df=2, max_df=0.7, max_features=50000, alpha=1.0 -> F1=0.6033\n",
            "[CNB] min_df=2, max_df=0.7, max_features=50000, alpha=1.0 -> F1=0.6927\n",
            "[MNB] min_df=2, max_df=0.7, max_features=50000, alpha=2.0 -> F1=0.5647\n",
            "[CNB] min_df=2, max_df=0.7, max_features=50000, alpha=2.0 -> F1=0.6864\n",
            "[MNB] min_df=5, max_df=0.9, max_features=None, alpha=0.1 -> F1=0.6736\n",
            "[CNB] min_df=5, max_df=0.9, max_features=None, alpha=0.1 -> F1=0.6766\n",
            "[MNB] min_df=5, max_df=0.9, max_features=None, alpha=0.5 -> F1=0.6383\n",
            "[CNB] min_df=5, max_df=0.9, max_features=None, alpha=0.5 -> F1=0.6842\n",
            "[MNB] min_df=5, max_df=0.9, max_features=None, alpha=1.0 -> F1=0.6098\n",
            "[CNB] min_df=5, max_df=0.9, max_features=None, alpha=1.0 -> F1=0.6838\n",
            "[MNB] min_df=5, max_df=0.9, max_features=None, alpha=2.0 -> F1=0.5706\n",
            "[CNB] min_df=5, max_df=0.9, max_features=None, alpha=2.0 -> F1=0.6818\n",
            "[MNB] min_df=5, max_df=0.9, max_features=20000, alpha=0.1 -> F1=0.6736\n",
            "[CNB] min_df=5, max_df=0.9, max_features=20000, alpha=0.1 -> F1=0.6766\n",
            "[MNB] min_df=5, max_df=0.9, max_features=20000, alpha=0.5 -> F1=0.6383\n",
            "[CNB] min_df=5, max_df=0.9, max_features=20000, alpha=0.5 -> F1=0.6842\n",
            "[MNB] min_df=5, max_df=0.9, max_features=20000, alpha=1.0 -> F1=0.6098\n",
            "[CNB] min_df=5, max_df=0.9, max_features=20000, alpha=1.0 -> F1=0.6838\n",
            "[MNB] min_df=5, max_df=0.9, max_features=20000, alpha=2.0 -> F1=0.5706\n",
            "[CNB] min_df=5, max_df=0.9, max_features=20000, alpha=2.0 -> F1=0.6818\n",
            "[MNB] min_df=5, max_df=0.9, max_features=50000, alpha=0.1 -> F1=0.6736\n",
            "[CNB] min_df=5, max_df=0.9, max_features=50000, alpha=0.1 -> F1=0.6766\n",
            "[MNB] min_df=5, max_df=0.9, max_features=50000, alpha=0.5 -> F1=0.6383\n",
            "[CNB] min_df=5, max_df=0.9, max_features=50000, alpha=0.5 -> F1=0.6842\n",
            "[MNB] min_df=5, max_df=0.9, max_features=50000, alpha=1.0 -> F1=0.6098\n",
            "[CNB] min_df=5, max_df=0.9, max_features=50000, alpha=1.0 -> F1=0.6838\n",
            "[MNB] min_df=5, max_df=0.9, max_features=50000, alpha=2.0 -> F1=0.5706\n",
            "[CNB] min_df=5, max_df=0.9, max_features=50000, alpha=2.0 -> F1=0.6818\n",
            "[MNB] min_df=5, max_df=0.8, max_features=None, alpha=0.1 -> F1=0.6737\n",
            "[CNB] min_df=5, max_df=0.8, max_features=None, alpha=0.1 -> F1=0.6764\n",
            "[MNB] min_df=5, max_df=0.8, max_features=None, alpha=0.5 -> F1=0.6387\n",
            "[CNB] min_df=5, max_df=0.8, max_features=None, alpha=0.5 -> F1=0.6840\n",
            "[MNB] min_df=5, max_df=0.8, max_features=None, alpha=1.0 -> F1=0.6132\n",
            "[CNB] min_df=5, max_df=0.8, max_features=None, alpha=1.0 -> F1=0.6838\n",
            "[MNB] min_df=5, max_df=0.8, max_features=None, alpha=2.0 -> F1=0.5777\n",
            "[CNB] min_df=5, max_df=0.8, max_features=None, alpha=2.0 -> F1=0.6819\n",
            "[MNB] min_df=5, max_df=0.8, max_features=20000, alpha=0.1 -> F1=0.6737\n",
            "[CNB] min_df=5, max_df=0.8, max_features=20000, alpha=0.1 -> F1=0.6764\n",
            "[MNB] min_df=5, max_df=0.8, max_features=20000, alpha=0.5 -> F1=0.6387\n",
            "[CNB] min_df=5, max_df=0.8, max_features=20000, alpha=0.5 -> F1=0.6840\n",
            "[MNB] min_df=5, max_df=0.8, max_features=20000, alpha=1.0 -> F1=0.6132\n",
            "[CNB] min_df=5, max_df=0.8, max_features=20000, alpha=1.0 -> F1=0.6838\n",
            "[MNB] min_df=5, max_df=0.8, max_features=20000, alpha=2.0 -> F1=0.5777\n",
            "[CNB] min_df=5, max_df=0.8, max_features=20000, alpha=2.0 -> F1=0.6819\n",
            "[MNB] min_df=5, max_df=0.8, max_features=50000, alpha=0.1 -> F1=0.6737\n",
            "[CNB] min_df=5, max_df=0.8, max_features=50000, alpha=0.1 -> F1=0.6764\n",
            "[MNB] min_df=5, max_df=0.8, max_features=50000, alpha=0.5 -> F1=0.6387\n",
            "[CNB] min_df=5, max_df=0.8, max_features=50000, alpha=0.5 -> F1=0.6840\n",
            "[MNB] min_df=5, max_df=0.8, max_features=50000, alpha=1.0 -> F1=0.6132\n",
            "[CNB] min_df=5, max_df=0.8, max_features=50000, alpha=1.0 -> F1=0.6838\n",
            "[MNB] min_df=5, max_df=0.8, max_features=50000, alpha=2.0 -> F1=0.5777\n",
            "[CNB] min_df=5, max_df=0.8, max_features=50000, alpha=2.0 -> F1=0.6819\n",
            "[MNB] min_df=5, max_df=0.7, max_features=None, alpha=0.1 -> F1=0.6746\n",
            "[CNB] min_df=5, max_df=0.7, max_features=None, alpha=0.1 -> F1=0.6763\n",
            "[MNB] min_df=5, max_df=0.7, max_features=None, alpha=0.5 -> F1=0.6389\n",
            "[CNB] min_df=5, max_df=0.7, max_features=None, alpha=0.5 -> F1=0.6839\n",
            "[MNB] min_df=5, max_df=0.7, max_features=None, alpha=1.0 -> F1=0.6152\n",
            "[CNB] min_df=5, max_df=0.7, max_features=None, alpha=1.0 -> F1=0.6836\n",
            "[MNB] min_df=5, max_df=0.7, max_features=None, alpha=2.0 -> F1=0.5817\n",
            "[CNB] min_df=5, max_df=0.7, max_features=None, alpha=2.0 -> F1=0.6822\n",
            "[MNB] min_df=5, max_df=0.7, max_features=20000, alpha=0.1 -> F1=0.6746\n",
            "[CNB] min_df=5, max_df=0.7, max_features=20000, alpha=0.1 -> F1=0.6763\n",
            "[MNB] min_df=5, max_df=0.7, max_features=20000, alpha=0.5 -> F1=0.6389\n",
            "[CNB] min_df=5, max_df=0.7, max_features=20000, alpha=0.5 -> F1=0.6839\n",
            "[MNB] min_df=5, max_df=0.7, max_features=20000, alpha=1.0 -> F1=0.6152\n",
            "[CNB] min_df=5, max_df=0.7, max_features=20000, alpha=1.0 -> F1=0.6836\n",
            "[MNB] min_df=5, max_df=0.7, max_features=20000, alpha=2.0 -> F1=0.5817\n",
            "[CNB] min_df=5, max_df=0.7, max_features=20000, alpha=2.0 -> F1=0.6822\n",
            "[MNB] min_df=5, max_df=0.7, max_features=50000, alpha=0.1 -> F1=0.6746\n",
            "[CNB] min_df=5, max_df=0.7, max_features=50000, alpha=0.1 -> F1=0.6763\n",
            "[MNB] min_df=5, max_df=0.7, max_features=50000, alpha=0.5 -> F1=0.6389\n",
            "[CNB] min_df=5, max_df=0.7, max_features=50000, alpha=0.5 -> F1=0.6839\n",
            "[MNB] min_df=5, max_df=0.7, max_features=50000, alpha=1.0 -> F1=0.6152\n",
            "[CNB] min_df=5, max_df=0.7, max_features=50000, alpha=1.0 -> F1=0.6836\n",
            "[MNB] min_df=5, max_df=0.7, max_features=50000, alpha=2.0 -> F1=0.5817\n",
            "[CNB] min_df=5, max_df=0.7, max_features=50000, alpha=2.0 -> F1=0.6822\n",
            "\n",
            "Resultados:\n",
            "\n",
            "MultinomialNB:\n",
            "  config: {'min_df': 2, 'max_df': 0.7, 'max_features': 20000, 'alpha': 0.1}\n",
            "  F1-macro: 0.6753414604968164\n",
            "\n",
            "ComplementNB:\n",
            "  config: {'min_df': 2, 'max_df': 0.9, 'max_features': None, 'alpha': 0.5}\n",
            "  F1-macro: 0.6980382854233241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De los experimentos realizados, respetando la restricción de no modificar el hiperparámetro ngram_range de los vectorizadores, se obtuvo que el mejor rendimiento lo obtuvo el ComplementNB, que supera por muy poco al MultinomialNB.\n",
        "\n",
        "Si lo comparamos con el clasificador zero-shot que alcanzó un F1-score (promedio macro) de **0.5050** y el modelo Naïve Bayes, que logró un F1-score de **0.5854**; ambos modelos implementados obtuvieron un rendimiento superior."
      ],
      "metadata": {
        "id": "-6xYonuOlAeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 4\n",
        "\n",
        "Transponer la matriz documento-término. De esa manera se obtiene una matriz término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares.\n",
        "\n",
        "**Elegir las palabras MANUALMENTE para evitar la aparición de términos poco interpretables**."
      ],
      "metadata": {
        "id": "drqDCWKLkbln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se pide transponer la matriz documento-termino.\n",
        "\n",
        "Al vectorizar, se obtiene: M (documento × término)\n",
        "\n",
        "Se necesita al transponerla: Mᵀ (término × documento)\n",
        "\n",
        "Se seleccionan 5 palabras al azar. Para ello, buscaremos las palabras mas frecuentes y seleccionaremos de manera manual las mas frecuentes que sean relevantes."
      ],
      "metadata": {
        "id": "IlsdRgDwURjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train = fetch_20newsgroups(\n",
        "    subset=\"train\",\n",
        "    remove=(\"headers\", \"footers\", \"quotes\")  #menos basura\n",
        ")\n",
        "tfidfvect = TfidfVectorizer(\n",
        "    stop_words=\"english\",\n",
        "    token_pattern=r\"(?u)\\b[a-zA-Z]{3,}\\b\",  # Opcion de filtrado para eliminar \"basura\"\n",
        "    min_df=3,   # opcional pero recomendable\n",
        "    max_df=0.85 # opcional\n",
        ")\n",
        "\n",
        "# Volvemos a vectorizar\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "idx2word = tfidfvect.get_feature_names_out()"
      ],
      "metadata": {
        "id": "1z5HO1sjMUqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_sums = X_train.sum(axis=0)\n",
        "\n",
        "# Convert the sparse matrix sum to a dense array for easier sorting\n",
        "term_sums_dense = np.asarray(term_sums).flatten()\n",
        "\n",
        "# Get the indices of the top 20 terms\n",
        "top_20_indices = term_sums_dense.argsort()[-20:][::-1]\n",
        "\n",
        "print(\"Los 20 términos más utilizados (según la suma de TF-IDF) son:\")\n",
        "for i, idx in enumerate(top_20_indices):\n",
        "    print(f\"{i+1}. {idx2word[idx]} (TF-IDF sum: {term_sums_dense[idx]:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4DQbqcDJ5ia",
        "outputId": "4878390b-5c0a-4648-d774-3154363efbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los 20 términos más utilizados (según la suma de TF-IDF) son:\n",
            "1. like (TF-IDF sum: 161.16)\n",
            "2. just (TF-IDF sum: 160.61)\n",
            "3. know (TF-IDF sum: 158.19)\n",
            "4. don (TF-IDF sum: 155.35)\n",
            "5. people (TF-IDF sum: 137.09)\n",
            "6. does (TF-IDF sum: 135.22)\n",
            "7. think (TF-IDF sum: 132.52)\n",
            "8. use (TF-IDF sum: 119.58)\n",
            "9. thanks (TF-IDF sum: 118.18)\n",
            "10. good (TF-IDF sum: 114.15)\n",
            "11. time (TF-IDF sum: 109.45)\n",
            "12. new (TF-IDF sum: 103.67)\n",
            "13. edu (TF-IDF sum: 91.82)\n",
            "14. need (TF-IDF sum: 88.68)\n",
            "15. god (TF-IDF sum: 88.29)\n",
            "16. make (TF-IDF sum: 87.06)\n",
            "17. windows (TF-IDF sum: 86.05)\n",
            "18. way (TF-IDF sum: 85.62)\n",
            "19. want (TF-IDF sum: 85.13)\n",
            "20. problem (TF-IDF sum: 84.01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se seleccionan las siguientes palabras\n",
        "selected_words=[\"god\", \"windows\", \"people\", \"problem\", \"time\"]"
      ],
      "metadata": {
        "id": "gQ2qJ7t1Vmm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_word_indices(words_list, vocabulary_array):\n",
        "    \"\"\"\n",
        "    Imprime palabra y el indice mas similar.\n",
        "\n",
        "    Args:\n",
        "        words_list (list): A list of words to find indices for.\n",
        "        vocabulary_array (np.ndarray): An array representing the vocabulary (idx2word).\n",
        "    \"\"\"\n",
        "    print(\"\\nÍndices:\")\n",
        "    for word in words_list:\n",
        "        try:\n",
        "            # Find the index of the word in the vocabulary\n",
        "            idx = np.where(vocabulary_array == word)[0][0]\n",
        "            print(f\"  Palabra: '{word}', Índice: {idx}\")\n",
        "        except IndexError:\n",
        "            print(f\"  Palabra: '{word}' no encontrada en el vocabulario.\")\n",
        "\n",
        "# Llama a la función con las palabras seleccionadas y el vocabulario\n",
        "print_word_indices(selected_words, idx2word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO6I9q0lO3Ux",
        "outputId": "233de5ec-0660-4efd-a4bb-6054d7015560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Índices:\n",
            "  Palabra: 'god', Índice: 8449\n",
            "  Palabra: 'windows', Índice: 22084\n",
            "  Palabra: 'people', Índice: 14666\n",
            "  Palabra: 'problem', Índice: 15573\n",
            "  Palabra: 'time', Índice: 20307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se construye la matriz transpuesta"
      ],
      "metadata": {
        "id": "9x6C_jV9WNRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se tiene X_train - documento × término\n",
        "X_words = X_train.T  # término × documento\n"
      ],
      "metadata": {
        "id": "DZBCnmTZWYCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_most_similar_words(word, X_words_matrix, vocabulary, top_n=5):\n",
        "    \"\"\"\n",
        "    Calcula y devuelve las N palabras más similares a una palabra dada.\n",
        "\n",
        "    Args:\n",
        "        word (str): La palabra para la que se buscarán similitudes.\n",
        "        X_words_matrix (csr_matrix): La matriz transpuesta (término x documento).\n",
        "        vocabulary (np.ndarray): Array que mapea índices a palabras.\n",
        "        top_n (int): Número de palabras más similares a devolver.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de tuplas (palabra, similitud) de las palabras más similares.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        word_idx = np.where(vocabulary == word)[0][0]\n",
        "    except IndexError:\n",
        "        return f\"La palabra '{word}' no se encontró en el vocabulario.\"\n",
        "\n",
        "    # Obtener el vector de la palabra de interés\n",
        "    word_vector = X_words_matrix[word_idx]\n",
        "\n",
        "    # Calcular la similitud coseno con todos los demás vectores de palabras\n",
        "    similarities = cosine_similarity(word_vector, X_words_matrix)[0]\n",
        "\n",
        "    # Excluir la palabra original (similaridad 1.0 consigo misma)\n",
        "    # y obtener los índices de las palabras más similares en orden descendente\n",
        "    most_similar_indices = np.argsort(similarities)[::-1][1:top_n + 1]\n",
        "\n",
        "    results = []\n",
        "    for idx in most_similar_indices:\n",
        "        sim_score = similarities[idx]\n",
        "        if sim_score > 0: # Solo considerar palabras con similitud > 0\n",
        "            results.append((vocabulary[idx], sim_score))\n",
        "    return results\n",
        "\n",
        "\n",
        "# Bucle para cada palabra seleccionada\n",
        "for word in selected_words:\n",
        "    print(f\"\\nPalabras más similares a '{word}':\")\n",
        "    similar_words = get_most_similar_words(word, X_words, idx2word)\n",
        "\n",
        "    if isinstance(similar_words, str):\n",
        "        print(similar_words)\n",
        "    elif similar_words:\n",
        "        for sim_word, score in similar_words:\n",
        "            print(f\"  - {sim_word}: {score:.4f}\")\n",
        "    else:\n",
        "        print(\"  No se encontraron palabras similares (con similitud > 0).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkRIWTLtTJ2n",
        "outputId": "5893ec73-2bbb-46e0-f809-7c062bd7c88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'god':\n",
            "  - jesus: 0.2819\n",
            "  - bible: 0.2775\n",
            "  - christ: 0.2717\n",
            "  - faith: 0.2594\n",
            "  - existence: 0.2476\n",
            "\n",
            "Palabras más similares a 'windows':\n",
            "  - dos: 0.3014\n",
            "  - microsoft: 0.2162\n",
            "  - running: 0.1903\n",
            "  - file: 0.1873\n",
            "  - hierarchies: 0.1831\n",
            "\n",
            "Palabras más similares a 'people':\n",
            "  - don: 0.2423\n",
            "  - think: 0.2295\n",
            "  - government: 0.2013\n",
            "  - just: 0.1879\n",
            "  - like: 0.1765\n",
            "\n",
            "Palabras más similares a 'problem':\n",
            "  - fix: 0.1968\n",
            "  - fixed: 0.1591\n",
            "  - solve: 0.1444\n",
            "  - using: 0.1381\n",
            "  - problems: 0.1341\n",
            "\n",
            "Palabras más similares a 'time':\n",
            "  - like: 0.1681\n",
            "  - long: 0.1612\n",
            "  - don: 0.1577\n",
            "  - just: 0.1512\n",
            "  - think: 0.1462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, se realizó nuevamente la similitud coseno, obteniendo valores bajos, pero relevantes.\n",
        "\n",
        "- Para god, todos los terminos tienen una estrecha relación con la religión.\n",
        "- Para windows, todos los terminos se asocian al software.\n",
        "- Para people, los terminos son muy amplios, pero aun asi, tienen relacion al debate, opinion.\n",
        "- Para problem, los terminos se relacionan claramente a los problemas.\n",
        "- Para time, tambien existe una relacion mas general, pero menos evidente. Por ejemplo, long time, just in time, etc.\n",
        "\n",
        "En conclusión, se permite identificar que tan similares son los terminos en funcion de los documentos que comparten."
      ],
      "metadata": {
        "id": "H5EYfGAdTJiM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}